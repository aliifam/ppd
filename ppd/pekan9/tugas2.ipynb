{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tugas 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Marital status</th>\n",
       "      <th>Application mode</th>\n",
       "      <th>Application order</th>\n",
       "      <th>Course</th>\n",
       "      <th>Daytime/evening attendance\\t</th>\n",
       "      <th>Previous qualification</th>\n",
       "      <th>Previous qualification (grade)</th>\n",
       "      <th>Nacionality</th>\n",
       "      <th>Mother's qualification</th>\n",
       "      <th>Father's qualification</th>\n",
       "      <th>...</th>\n",
       "      <th>Curricular units 2nd sem (credited)</th>\n",
       "      <th>Curricular units 2nd sem (enrolled)</th>\n",
       "      <th>Curricular units 2nd sem (evaluations)</th>\n",
       "      <th>Curricular units 2nd sem (approved)</th>\n",
       "      <th>Curricular units 2nd sem (grade)</th>\n",
       "      <th>Curricular units 2nd sem (without evaluations)</th>\n",
       "      <th>Unemployment rate</th>\n",
       "      <th>Inflation rate</th>\n",
       "      <th>GDP</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>171</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.74</td>\n",
       "      <td>Dropout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>9254</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>13.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.79</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>9070</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.74</td>\n",
       "      <td>Dropout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>9773</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>12.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-3.12</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>8014</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.79</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Marital status  Application mode  Application order  Course  \\\n",
       "0               1                17                  5     171   \n",
       "1               1                15                  1    9254   \n",
       "2               1                 1                  5    9070   \n",
       "3               1                17                  2    9773   \n",
       "4               2                39                  1    8014   \n",
       "\n",
       "   Daytime/evening attendance\\t  Previous qualification  \\\n",
       "0                             1                       1   \n",
       "1                             1                       1   \n",
       "2                             1                       1   \n",
       "3                             1                       1   \n",
       "4                             0                       1   \n",
       "\n",
       "   Previous qualification (grade)  Nacionality  Mother's qualification  \\\n",
       "0                           122.0            1                      19   \n",
       "1                           160.0            1                       1   \n",
       "2                           122.0            1                      37   \n",
       "3                           122.0            1                      38   \n",
       "4                           100.0            1                      37   \n",
       "\n",
       "   Father's qualification  ...  Curricular units 2nd sem (credited)  \\\n",
       "0                      12  ...                                    0   \n",
       "1                       3  ...                                    0   \n",
       "2                      37  ...                                    0   \n",
       "3                      37  ...                                    0   \n",
       "4                      38  ...                                    0   \n",
       "\n",
       "   Curricular units 2nd sem (enrolled)  \\\n",
       "0                                    0   \n",
       "1                                    6   \n",
       "2                                    6   \n",
       "3                                    6   \n",
       "4                                    6   \n",
       "\n",
       "   Curricular units 2nd sem (evaluations)  \\\n",
       "0                                       0   \n",
       "1                                       6   \n",
       "2                                       0   \n",
       "3                                      10   \n",
       "4                                       6   \n",
       "\n",
       "   Curricular units 2nd sem (approved)  Curricular units 2nd sem (grade)  \\\n",
       "0                                    0                          0.000000   \n",
       "1                                    6                         13.666667   \n",
       "2                                    0                          0.000000   \n",
       "3                                    5                         12.400000   \n",
       "4                                    6                         13.000000   \n",
       "\n",
       "   Curricular units 2nd sem (without evaluations)  Unemployment rate  \\\n",
       "0                                               0               10.8   \n",
       "1                                               0               13.9   \n",
       "2                                               0               10.8   \n",
       "3                                               0                9.4   \n",
       "4                                               0               13.9   \n",
       "\n",
       "   Inflation rate   GDP    Target  \n",
       "0             1.4  1.74   Dropout  \n",
       "1            -0.3  0.79  Graduate  \n",
       "2             1.4  1.74   Dropout  \n",
       "3            -0.8 -3.12  Graduate  \n",
       "4            -0.3  0.79  Graduate  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/data.csv', sep=';')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualizing target class distribution\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df['Target'].value_counts().plot(kind='pie', autopct='%1.1f%%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4424 entries, 0 to 4423\n",
      "Data columns (total 37 columns):\n",
      " #   Column                                          Non-Null Count  Dtype  \n",
      "---  ------                                          --------------  -----  \n",
      " 0   Marital status                                  4424 non-null   int64  \n",
      " 1   Application mode                                4424 non-null   int64  \n",
      " 2   Application order                               4424 non-null   int64  \n",
      " 3   Course                                          4424 non-null   int64  \n",
      " 4   Daytime/evening attendance\t                     4424 non-null   int64  \n",
      " 5   Previous qualification                          4424 non-null   int64  \n",
      " 6   Previous qualification (grade)                  4424 non-null   float64\n",
      " 7   Nacionality                                     4424 non-null   int64  \n",
      " 8   Mother's qualification                          4424 non-null   int64  \n",
      " 9   Father's qualification                          4424 non-null   int64  \n",
      " 10  Mother's occupation                             4424 non-null   int64  \n",
      " 11  Father's occupation                             4424 non-null   int64  \n",
      " 12  Admission grade                                 4424 non-null   float64\n",
      " 13  Displaced                                       4424 non-null   int64  \n",
      " 14  Educational special needs                       4424 non-null   int64  \n",
      " 15  Debtor                                          4424 non-null   int64  \n",
      " 16  Tuition fees up to date                         4424 non-null   int64  \n",
      " 17  Gender                                          4424 non-null   int64  \n",
      " 18  Scholarship holder                              4424 non-null   int64  \n",
      " 19  Age at enrollment                               4424 non-null   int64  \n",
      " 20  International                                   4424 non-null   int64  \n",
      " 21  Curricular units 1st sem (credited)             4424 non-null   int64  \n",
      " 22  Curricular units 1st sem (enrolled)             4424 non-null   int64  \n",
      " 23  Curricular units 1st sem (evaluations)          4424 non-null   int64  \n",
      " 24  Curricular units 1st sem (approved)             4424 non-null   int64  \n",
      " 25  Curricular units 1st sem (grade)                4424 non-null   float64\n",
      " 26  Curricular units 1st sem (without evaluations)  4424 non-null   int64  \n",
      " 27  Curricular units 2nd sem (credited)             4424 non-null   int64  \n",
      " 28  Curricular units 2nd sem (enrolled)             4424 non-null   int64  \n",
      " 29  Curricular units 2nd sem (evaluations)          4424 non-null   int64  \n",
      " 30  Curricular units 2nd sem (approved)             4424 non-null   int64  \n",
      " 31  Curricular units 2nd sem (grade)                4424 non-null   float64\n",
      " 32  Curricular units 2nd sem (without evaluations)  4424 non-null   int64  \n",
      " 33  Unemployment rate                               4424 non-null   float64\n",
      " 34  Inflation rate                                  4424 non-null   float64\n",
      " 35  GDP                                             4424 non-null   float64\n",
      " 36  Target                                          4424 non-null   object \n",
      "dtypes: float64(7), int64(29), object(1)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Marital status                                    0\n",
       "Application mode                                  0\n",
       "Application order                                 0\n",
       "Course                                            0\n",
       "Daytime/evening attendance\\t                      0\n",
       "Previous qualification                            0\n",
       "Previous qualification (grade)                    0\n",
       "Nacionality                                       0\n",
       "Mother's qualification                            0\n",
       "Father's qualification                            0\n",
       "Mother's occupation                               0\n",
       "Father's occupation                               0\n",
       "Admission grade                                   0\n",
       "Displaced                                         0\n",
       "Educational special needs                         0\n",
       "Debtor                                            0\n",
       "Tuition fees up to date                           0\n",
       "Gender                                            0\n",
       "Scholarship holder                                0\n",
       "Age at enrollment                                 0\n",
       "International                                     0\n",
       "Curricular units 1st sem (credited)               0\n",
       "Curricular units 1st sem (enrolled)               0\n",
       "Curricular units 1st sem (evaluations)            0\n",
       "Curricular units 1st sem (approved)               0\n",
       "Curricular units 1st sem (grade)                  0\n",
       "Curricular units 1st sem (without evaluations)    0\n",
       "Curricular units 2nd sem (credited)               0\n",
       "Curricular units 2nd sem (enrolled)               0\n",
       "Curricular units 2nd sem (evaluations)            0\n",
       "Curricular units 2nd sem (approved)               0\n",
       "Curricular units 2nd sem (grade)                  0\n",
       "Curricular units 2nd sem (without evaluations)    0\n",
       "Unemployment rate                                 0\n",
       "Inflation rate                                    0\n",
       "GDP                                               0\n",
       "Target                                            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Marital status</th>\n",
       "      <th>Application mode</th>\n",
       "      <th>Application order</th>\n",
       "      <th>Course</th>\n",
       "      <th>Daytime/evening attendance\\t</th>\n",
       "      <th>Previous qualification</th>\n",
       "      <th>Previous qualification (grade)</th>\n",
       "      <th>Nacionality</th>\n",
       "      <th>Mother's qualification</th>\n",
       "      <th>Father's qualification</th>\n",
       "      <th>...</th>\n",
       "      <th>Curricular units 2nd sem (credited)</th>\n",
       "      <th>Curricular units 2nd sem (enrolled)</th>\n",
       "      <th>Curricular units 2nd sem (evaluations)</th>\n",
       "      <th>Curricular units 2nd sem (approved)</th>\n",
       "      <th>Curricular units 2nd sem (grade)</th>\n",
       "      <th>Curricular units 2nd sem (without evaluations)</th>\n",
       "      <th>Unemployment rate</th>\n",
       "      <th>Inflation rate</th>\n",
       "      <th>GDP</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>171</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.74</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>9254</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>13.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.79</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>9070</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.74</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>9773</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>12.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-3.12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>8014</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.79</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Marital status  Application mode  Application order  Course  \\\n",
       "0               1                17                  5     171   \n",
       "1               1                15                  1    9254   \n",
       "2               1                 1                  5    9070   \n",
       "3               1                17                  2    9773   \n",
       "4               2                39                  1    8014   \n",
       "\n",
       "   Daytime/evening attendance\\t  Previous qualification  \\\n",
       "0                             1                       1   \n",
       "1                             1                       1   \n",
       "2                             1                       1   \n",
       "3                             1                       1   \n",
       "4                             0                       1   \n",
       "\n",
       "   Previous qualification (grade)  Nacionality  Mother's qualification  \\\n",
       "0                           122.0            1                      19   \n",
       "1                           160.0            1                       1   \n",
       "2                           122.0            1                      37   \n",
       "3                           122.0            1                      38   \n",
       "4                           100.0            1                      37   \n",
       "\n",
       "   Father's qualification  ...  Curricular units 2nd sem (credited)  \\\n",
       "0                      12  ...                                    0   \n",
       "1                       3  ...                                    0   \n",
       "2                      37  ...                                    0   \n",
       "3                      37  ...                                    0   \n",
       "4                      38  ...                                    0   \n",
       "\n",
       "   Curricular units 2nd sem (enrolled)  \\\n",
       "0                                    0   \n",
       "1                                    6   \n",
       "2                                    6   \n",
       "3                                    6   \n",
       "4                                    6   \n",
       "\n",
       "   Curricular units 2nd sem (evaluations)  \\\n",
       "0                                       0   \n",
       "1                                       6   \n",
       "2                                       0   \n",
       "3                                      10   \n",
       "4                                       6   \n",
       "\n",
       "   Curricular units 2nd sem (approved)  Curricular units 2nd sem (grade)  \\\n",
       "0                                    0                          0.000000   \n",
       "1                                    6                         13.666667   \n",
       "2                                    0                          0.000000   \n",
       "3                                    5                         12.400000   \n",
       "4                                    6                         13.000000   \n",
       "\n",
       "   Curricular units 2nd sem (without evaluations)  Unemployment rate  \\\n",
       "0                                               0               10.8   \n",
       "1                                               0               13.9   \n",
       "2                                               0               10.8   \n",
       "3                                               0                9.4   \n",
       "4                                               0               13.9   \n",
       "\n",
       "   Inflation rate   GDP  Target  \n",
       "0             1.4  1.74       0  \n",
       "1            -0.3  0.79       2  \n",
       "2             1.4  1.74       0  \n",
       "3            -0.8 -3.12       2  \n",
       "4            -0.3  0.79       2  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['Target'] = le.fit_transform(df['Target'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6587570621468927\n",
      "Precision: 0.5595983554712207\n",
      "Recall: 0.5200971444149282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aliif/Documents/kuliah/semester6/belajar-pandas/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# logistic regression original dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "df_X = df.drop('Target', axis=1)\n",
    "df_y = df['Target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X, df_y, test_size=0.2, random_state=42)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred, average='macro'))\n",
    "print('Recall:', recall_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6268343815513627\n",
      "Precision: 0.624316325934823\n",
      "Recall: 0.6244325686963964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aliif/Documents/kuliah/semester6/belajar-pandas/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# logistic regression with under-sampling\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "under_sampling = RandomUnderSampler(random_state=42)\n",
    "\n",
    "X_under, y_under = under_sampling.fit_resample(df_X, df_y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_under, y_under, test_size=0.2, random_state=42)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred, average='macro'))\n",
    "print('Recall:', recall_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5761689291101055\n",
      "Precision: 0.5795453033642632\n",
      "Recall: 0.5758022120188341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aliif/Documents/kuliah/semester6/belajar-pandas/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# logistic regression with over-sampling\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "over_sampling = RandomOverSampler(random_state=42)\n",
    "\n",
    "X_over, y_over = over_sampling.fit_resample(df_X, df_y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_over, y_over, test_size=0.2, random_state=42)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred, average='macro'))\n",
    "print('Recall:', recall_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6289592760180995\n",
      "Precision: 0.6316331950086371\n",
      "Recall: 0.6287171286117177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aliif/Documents/kuliah/semester6/belajar-pandas/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# logistic regression with SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "X_smote, y_smote = smote.fit_resample(df_X, df_y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smote, y_smote, test_size=0.2, random_state=42)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred, average='macro'))\n",
    "print('Recall:', recall_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5976653696498054\n",
      "Precision: 0.595913262163445\n",
      "Recall: 0.594274057804543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aliif/Documents/kuliah/semester6/belajar-pandas/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# logistic regression with ADASYN\n",
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "adasyn = ADASYN(random_state=42)\n",
    "\n",
    "X_adasyn, y_adasyn = adasyn.fit_resample(df_X, df_y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_adasyn, y_adasyn, test_size=0.2, random_state=42)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred, average='macro'))\n",
    "print('Recall:', recall_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6711864406779661\n",
      "Precision: 0.6152879242456641\n",
      "Recall: 0.6116933483236742\n"
     ]
    }
   ],
   "source": [
    "# decision tree original dataset\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X, df_y, test_size=0.2, random_state=42)\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred, average='macro'))\n",
    "print('Recall:', recall_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.59958071278826\n",
      "Precision: 0.6010888798148905\n",
      "Recall: 0.5984353779464567\n"
     ]
    }
   ],
   "source": [
    "# decision tree with under-sampling\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "under_sampling = RandomUnderSampler(random_state=42)\n",
    "\n",
    "X_under, y_under = under_sampling.fit_resample(df_X, df_y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_under, y_under, test_size=0.2, random_state=42)\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred, average='macro'))\n",
    "print('Recall:', recall_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8386123680241327\n",
      "Precision: 0.8413596985490915\n",
      "Recall: 0.8388298454925871\n"
     ]
    }
   ],
   "source": [
    "# decision tree with over-sampling\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "over_sampling = RandomOverSampler(random_state=42)\n",
    "\n",
    "X_over, y_over = over_sampling.fit_resample(df_X, df_y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_over, y_over, test_size=0.2, random_state=42)\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred, average='macro'))\n",
    "print('Recall:', recall_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7383107088989442\n",
      "Precision: 0.7396601250462241\n",
      "Recall: 0.7382136683493656\n"
     ]
    }
   ],
   "source": [
    "# decision tree with SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "X_smote, y_smote = smote.fit_resample(df_X, df_y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smote, y_smote, test_size=0.2, random_state=42)\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred, average='macro'))\n",
    "print('Recall:', recall_score(y_test, y_pred, average='macro'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7105058365758755\n",
      "Precision: 0.7120182205778754\n",
      "Recall: 0.7103527022304753\n"
     ]
    }
   ],
   "source": [
    "# decision tree with ADASYN\n",
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "adasyn = ADASYN(random_state=42)\n",
    "\n",
    "X_adasyn, y_adasyn = adasyn.fit_resample(df_X, df_y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_adasyn, y_adasyn, test_size=0.2, random_state=42)\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred, average='macro'))\n",
    "print('Recall:', recall_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7581920903954802\n",
      "Precision: 0.6890034007108534\n",
      "Recall: 0.6614699505300032\n"
     ]
    }
   ],
   "source": [
    "# random forest original dataset\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X, df_y, test_size=0.2, random_state=42)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred, average='macro'))\n",
    "print('Recall:', recall_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.710691823899371\n",
      "Precision: 0.7143313823660767\n",
      "Recall: 0.7091519227549256\n"
     ]
    }
   ],
   "source": [
    "# random forest with under-sampling\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "under_sampling = RandomUnderSampler(random_state=42)\n",
    "\n",
    "X_under, y_under = under_sampling.fit_resample(df_X, df_y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_under, y_under, test_size=0.2, random_state=42)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred, average='macro'))\n",
    "print('Recall:', recall_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8996983408748115\n",
      "Precision: 0.9015666040307541\n",
      "Recall: 0.8998175996509991\n"
     ]
    }
   ],
   "source": [
    "# random forest with over-sampling\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "over_sampling = RandomOverSampler(random_state=42)\n",
    "\n",
    "X_over, y_over = over_sampling.fit_resample(df_X, df_y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_over, y_over, test_size=0.2, random_state=42)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred, average='macro'))\n",
    "print('Recall:', recall_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8378582202111614\n",
      "Precision: 0.8421858417093651\n",
      "Recall: 0.8378814251346736\n"
     ]
    }
   ],
   "source": [
    "# random forest with SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "X_smote, y_smote = smote.fit_resample(df_X, df_y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smote, y_smote, test_size=0.2, random_state=42)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred, average='macro'))\n",
    "print('Recall:', recall_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.798443579766537\n",
      "Precision: 0.8031909506831608\n",
      "Recall: 0.7979728174464827\n"
     ]
    }
   ],
   "source": [
    "# random forest with ADASYN\n",
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "adasyn = ADASYN(random_state=42)\n",
    "\n",
    "X_adasyn, y_adasyn = adasyn.fit_resample(df_X, df_y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_adasyn, y_adasyn, test_size=0.2, random_state=42)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred, average='macro'))\n",
    "print('Recall:', recall_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aliif/Documents/kuliah/semester6/belajar-pandas/.venv/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7435028248587571\n",
      "Precision: 0.6656963838166846\n",
      "Recall: 0.6435380292996187\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost original dataset\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X, df_y, test_size=0.2, random_state=42)\n",
    "\n",
    "ab = AdaBoostClassifier()\n",
    "ab.fit(X_train, y_train)\n",
    "y_pred = ab.predict(X_test)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred, average='macro'))\n",
    "print('Recall:', recall_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aliif/Documents/kuliah/semester6/belajar-pandas/.venv/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6918238993710691\n",
      "Precision: 0.6914133134026086\n",
      "Recall: 0.6894908267487382\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost with under-sampling\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "under_sampling = RandomUnderSampler(random_state=42)\n",
    "\n",
    "X_under, y_under = under_sampling.fit_resample(df_X, df_y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_under, y_under, test_size=0.2, random_state=42)\n",
    "\n",
    "ab = AdaBoostClassifier()\n",
    "ab.fit(X_train, y_train)\n",
    "y_pred = ab.predict(X_test)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred, average='macro'))\n",
    "print('Recall:', recall_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aliif/Documents/kuliah/semester6/belajar-pandas/.venv/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7058823529411765\n",
      "Precision: 0.7073580909197347\n",
      "Recall: 0.705628568041604\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost with OverSampling\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "over_sampling = RandomOverSampler(random_state=42)\n",
    "\n",
    "X_over, y_over = over_sampling.fit_resample(df_X, df_y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_over, y_over, test_size=0.2, random_state=42)\n",
    "\n",
    "ab = AdaBoostClassifier()\n",
    "ab.fit(X_train, y_train)\n",
    "y_pred = ab.predict(X_test)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred, average='macro'))\n",
    "print('Recall:', recall_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aliif/Documents/kuliah/semester6/belajar-pandas/.venv/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7616892911010558\n",
      "Precision: 0.7677085789451695\n",
      "Recall: 0.7616830670867909\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost with SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "X_smote, y_smote = smote.fit_resample(df_X, df_y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smote, y_smote, test_size=0.2, random_state=42)\n",
    "\n",
    "ab = AdaBoostClassifier()\n",
    "ab.fit(X_train, y_train)\n",
    "y_pred = ab.predict(X_test)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred, average='macro'))\n",
    "print('Recall:', recall_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aliif/Documents/kuliah/semester6/belajar-pandas/.venv/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7245136186770428\n",
      "Precision: 0.7253856026007924\n",
      "Recall: 0.7229789949752022\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost with ADASYN\n",
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "adasyn = ADASYN(random_state=42)\n",
    "\n",
    "X_adasyn, y_adasyn = adasyn.fit_resample(df_X, df_y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_adasyn, y_adasyn, test_size=0.2, random_state=42)\n",
    "\n",
    "ab = AdaBoostClassifier()\n",
    "ab.fit(X_train, y_train)\n",
    "y_pred = ab.predict(X_test)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred, average='macro'))\n",
    "print('Recall:', recall_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8994350282485876\n",
      "Precision: 0.872911222760838\n",
      "Recall: 0.8937530174211239\n"
     ]
    }
   ],
   "source": [
    "# KNN with original dataset\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X, df_y, test_size=0.2, random_state=42)\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred, average='macro'))\n",
    "print('Recall:', recall_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9371069182389937\n",
      "Precision: 0.9374324885749896\n",
      "Recall: 0.9363523469330803\n"
     ]
    }
   ],
   "source": [
    "# KNN with under sampling\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "under_sampling = RandomUnderSampler(random_state=42)\n",
    "\n",
    "X_under, y_under = under_sampling.fit_resample(df_X, df_y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_under, y_under, test_size=0.2, random_state=42)\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred, average='macro'))\n",
    "print('Recall:', recall_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8567119155354449\n",
      "Precision: 0.8571815023575171\n",
      "Recall: 0.8567377043482187\n"
     ]
    }
   ],
   "source": [
    "# KNN with over sampling\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "over_sampling = RandomOverSampler(random_state=42)\n",
    "\n",
    "X_over, y_over = over_sampling.fit_resample(df_X, df_y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_over, y_over, test_size=0.2, random_state=42)\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred, average='macro'))\n",
    "print('Recall:', recall_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8129713423831071\n",
      "Precision: 0.8128261737311124\n",
      "Recall: 0.8128435824358736\n"
     ]
    }
   ],
   "source": [
    "# KNN with SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "X_smote, y_smote = smote.fit_resample(df_X, df_y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smote, y_smote, test_size=0.2, random_state=42)\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred, average='macro'))\n",
    "print('Recall:', recall_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7105058365758755\n",
      "Precision: 0.7120182205778754\n",
      "Recall: 0.7103527022304753\n"
     ]
    }
   ],
   "source": [
    "# KNN wiht ADASYN\n",
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "adasyn = ADASYN(random_state=42)\n",
    "\n",
    "X_adasyn, y_adasyn = adasyn.fit_resample(df_X, df_y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_adasyn, y_adasyn, test_size=0.2, random_state=42)\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred, average='macro'))\n",
    "print('Recall:', recall_score(y_test, y_pred, average='macro'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
